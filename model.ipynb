{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       job_id                                              title  \\\n",
      "0           1                                   Marketing Intern   \n",
      "1           2          Customer Service - Cloud Video Production   \n",
      "2           3            Commissioning Machinery Assistant (CMA)   \n",
      "3           4                  Account Executive - Washington DC   \n",
      "4           5                                Bill Review Manager   \n",
      "...       ...                                                ...   \n",
      "17875   17876                   Account Director - Distribution    \n",
      "17876   17877                                 Payroll Accountant   \n",
      "17877   17878  Project Cost Control Staff Engineer - Cost Con...   \n",
      "17878   17879                                   Graphic Designer   \n",
      "17879   17880                         Web Application Developers   \n",
      "\n",
      "                   location   department salary_range  \\\n",
      "0          US, NY, New York    Marketing          NaN   \n",
      "1            NZ, , Auckland      Success          NaN   \n",
      "2             US, IA, Wever          NaN          NaN   \n",
      "3        US, DC, Washington        Sales          NaN   \n",
      "4        US, FL, Fort Worth          NaN          NaN   \n",
      "...                     ...          ...          ...   \n",
      "17875       CA, ON, Toronto        Sales          NaN   \n",
      "17876  US, PA, Philadelphia   Accounting          NaN   \n",
      "17877       US, TX, Houston          NaN          NaN   \n",
      "17878         NG, LA, Lagos          NaN          NaN   \n",
      "17879     NZ, N, Wellington  Engineering          NaN   \n",
      "\n",
      "                                         company_profile  \\\n",
      "0      We're Food52, and we've created a groundbreaki...   \n",
      "1      90 Seconds, the worlds Cloud Video Production ...   \n",
      "2      Valor Services provides Workforce Solutions th...   \n",
      "3      Our passion for improving quality of life thro...   \n",
      "4      SpotSource Solutions LLC is a Global Human Cap...   \n",
      "...                                                  ...   \n",
      "17875  Vend is looking for some awesome new talent to...   \n",
      "17876  WebLinc is the e-commerce platform and service...   \n",
      "17877  We Provide Full Time Permanent Positions for m...   \n",
      "17878                                                NaN   \n",
      "17879  Vend is looking for some awesome new talent to...   \n",
      "\n",
      "                                             description  \\\n",
      "0      Food52, a fast-growing, James Beard Award-winn...   \n",
      "1      Organised - Focused - Vibrant - Awesome!Do you...   \n",
      "2      Our client, located in Houston, is actively se...   \n",
      "3      THE COMPANY: ESRI – Environmental Systems Rese...   \n",
      "4      JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
      "...                                                  ...   \n",
      "17875  Just in case this is the first time you’ve vis...   \n",
      "17876  The Payroll Accountant will focus primarily on...   \n",
      "17877  Experienced Project Cost Control Staff Enginee...   \n",
      "17878  Nemsia Studios is looking for an experienced v...   \n",
      "17879  Who are we?Vend is an award winning web based ...   \n",
      "\n",
      "                                            requirements  \\\n",
      "0      Experience with content management systems a m...   \n",
      "1      What we expect from you:Your key responsibilit...   \n",
      "2      Implement pre-commissioning and commissioning ...   \n",
      "3      EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
      "4      QUALIFICATIONS:RN license in the State of Texa...   \n",
      "...                                                  ...   \n",
      "17875  To ace this role you:Will eat comprehensive St...   \n",
      "17876  - B.A. or B.S. in Accounting- Desire to have f...   \n",
      "17877  At least 12 years professional experience.Abil...   \n",
      "17878  1. Must be fluent in the latest versions of Co...   \n",
      "17879  We want to hear from you if:You have an in-dep...   \n",
      "\n",
      "                                                benefits  telecommuting  \\\n",
      "0                                                    NaN              0   \n",
      "1      What you will get from usThrough being part of...              0   \n",
      "2                                                    NaN              0   \n",
      "3      Our culture is anything but corporate—we have ...              0   \n",
      "4                                  Full Benefits Offered              0   \n",
      "...                                                  ...            ...   \n",
      "17875  What can you expect from us?We have an open cu...              0   \n",
      "17876  Health &amp; WellnessMedical planPrescription ...              0   \n",
      "17877                                                NaN              0   \n",
      "17878  Competitive salary (compensation will be based...              0   \n",
      "17879                                                NaN              0   \n",
      "\n",
      "       has_company_logo  has_questions employment_type required_experience  \\\n",
      "0                     1              0           Other          Internship   \n",
      "1                     1              0       Full-time      Not Applicable   \n",
      "2                     1              0             NaN                 NaN   \n",
      "3                     1              0       Full-time    Mid-Senior level   \n",
      "4                     1              1       Full-time    Mid-Senior level   \n",
      "...                 ...            ...             ...                 ...   \n",
      "17875                 1              1       Full-time    Mid-Senior level   \n",
      "17876                 1              1       Full-time    Mid-Senior level   \n",
      "17877                 0              0       Full-time                 NaN   \n",
      "17878                 0              1        Contract      Not Applicable   \n",
      "17879                 1              1       Full-time    Mid-Senior level   \n",
      "\n",
      "      required_education                   industry              function  \\\n",
      "0                    NaN                        NaN             Marketing   \n",
      "1                    NaN  Marketing and Advertising      Customer Service   \n",
      "2                    NaN                        NaN                   NaN   \n",
      "3      Bachelor's Degree          Computer Software                 Sales   \n",
      "4      Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
      "...                  ...                        ...                   ...   \n",
      "17875                NaN          Computer Software                 Sales   \n",
      "17876  Bachelor's Degree                   Internet   Accounting/Auditing   \n",
      "17877                NaN                        NaN                   NaN   \n",
      "17878       Professional             Graphic Design                Design   \n",
      "17879                NaN          Computer Software           Engineering   \n",
      "\n",
      "       fraudulent  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "...           ...  \n",
      "17875           0  \n",
      "17876           0  \n",
      "17877           0  \n",
      "17878           0  \n",
      "17879           0  \n",
      "\n",
      "[17880 rows x 18 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('fake_job_postings.csv')\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                         company_profile  \\\n",
      "0      We're Food52, and we've created a groundbreaki...   \n",
      "1      90 Seconds, the worlds Cloud Video Production ...   \n",
      "2      Valor Services provides Workforce Solutions th...   \n",
      "3      Our passion for improving quality of life thro...   \n",
      "4      SpotSource Solutions LLC is a Global Human Cap...   \n",
      "...                                                  ...   \n",
      "17875  Vend is looking for some awesome new talent to...   \n",
      "17876  WebLinc is the e-commerce platform and service...   \n",
      "17877  We Provide Full Time Permanent Positions for m...   \n",
      "17878                                                NaN   \n",
      "17879  Vend is looking for some awesome new talent to...   \n",
      "\n",
      "                                             description  \\\n",
      "0      Food52, a fast-growing, James Beard Award-winn...   \n",
      "1      Organised - Focused - Vibrant - Awesome!Do you...   \n",
      "2      Our client, located in Houston, is actively se...   \n",
      "3      THE COMPANY: ESRI – Environmental Systems Rese...   \n",
      "4      JOB TITLE: Itemization Review ManagerLOCATION:...   \n",
      "...                                                  ...   \n",
      "17875  Just in case this is the first time you’ve vis...   \n",
      "17876  The Payroll Accountant will focus primarily on...   \n",
      "17877  Experienced Project Cost Control Staff Enginee...   \n",
      "17878  Nemsia Studios is looking for an experienced v...   \n",
      "17879  Who are we?Vend is an award winning web based ...   \n",
      "\n",
      "                                            requirements  \\\n",
      "0      Experience with content management systems a m...   \n",
      "1      What we expect from you:Your key responsibilit...   \n",
      "2      Implement pre-commissioning and commissioning ...   \n",
      "3      EDUCATION: Bachelor’s or Master’s in GIS, busi...   \n",
      "4      QUALIFICATIONS:RN license in the State of Texa...   \n",
      "...                                                  ...   \n",
      "17875  To ace this role you:Will eat comprehensive St...   \n",
      "17876  - B.A. or B.S. in Accounting- Desire to have f...   \n",
      "17877  At least 12 years professional experience.Abil...   \n",
      "17878  1. Must be fluent in the latest versions of Co...   \n",
      "17879  We want to hear from you if:You have an in-dep...   \n",
      "\n",
      "                                                benefits  telecommuting  \\\n",
      "0                                                    NaN              0   \n",
      "1      What you will get from usThrough being part of...              0   \n",
      "2                                                    NaN              0   \n",
      "3      Our culture is anything but corporate—we have ...              0   \n",
      "4                                  Full Benefits Offered              0   \n",
      "...                                                  ...            ...   \n",
      "17875  What can you expect from us?We have an open cu...              0   \n",
      "17876  Health &amp; WellnessMedical planPrescription ...              0   \n",
      "17877                                                NaN              0   \n",
      "17878  Competitive salary (compensation will be based...              0   \n",
      "17879                                                NaN              0   \n",
      "\n",
      "       has_company_logo  has_questions employment_type required_experience  \\\n",
      "0                     1              0           Other          Internship   \n",
      "1                     1              0       Full-time      Not Applicable   \n",
      "2                     1              0             NaN                 NaN   \n",
      "3                     1              0       Full-time    Mid-Senior level   \n",
      "4                     1              1       Full-time    Mid-Senior level   \n",
      "...                 ...            ...             ...                 ...   \n",
      "17875                 1              1       Full-time    Mid-Senior level   \n",
      "17876                 1              1       Full-time    Mid-Senior level   \n",
      "17877                 0              0       Full-time                 NaN   \n",
      "17878                 0              1        Contract      Not Applicable   \n",
      "17879                 1              1       Full-time    Mid-Senior level   \n",
      "\n",
      "      required_education                   industry              function  \\\n",
      "0                    NaN                        NaN             Marketing   \n",
      "1                    NaN  Marketing and Advertising      Customer Service   \n",
      "2                    NaN                        NaN                   NaN   \n",
      "3      Bachelor's Degree          Computer Software                 Sales   \n",
      "4      Bachelor's Degree     Hospital & Health Care  Health Care Provider   \n",
      "...                  ...                        ...                   ...   \n",
      "17875                NaN          Computer Software                 Sales   \n",
      "17876  Bachelor's Degree                   Internet   Accounting/Auditing   \n",
      "17877                NaN                        NaN                   NaN   \n",
      "17878       Professional             Graphic Design                Design   \n",
      "17879                NaN          Computer Software           Engineering   \n",
      "\n",
      "       fraudulent  \n",
      "0               0  \n",
      "1               0  \n",
      "2               0  \n",
      "3               0  \n",
      "4               0  \n",
      "...           ...  \n",
      "17875           0  \n",
      "17876           0  \n",
      "17877           0  \n",
      "17878           0  \n",
      "17879           0  \n",
      "\n",
      "[17880 rows x 13 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(columns = [\"job_id\",\"title\",\"location\",\"department\",\"salary_range\"])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_profile         True\n",
       "description             True\n",
       "requirements            True\n",
       "benefits                True\n",
       "telecommuting          False\n",
       "has_company_logo       False\n",
       "has_questions          False\n",
       "employment_type         True\n",
       "required_experience     True\n",
       "required_education      True\n",
       "industry                True\n",
       "function                True\n",
       "fraudulent             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['employment_type'] = df['employment_type'].fillna('Other')\n",
    "df['required_experience'] = df['required_experience'].fillna('Not Applicable')\n",
    "df[\"required_education\"] = df[\"required_education\"].fillna('Unspecified')\n",
    "df['industry'] = df['industry'].fillna(\"Other\")\n",
    "df['function'] = df['function'].fillna(\"Other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_profile         True\n",
       "description             True\n",
       "requirements            True\n",
       "benefits                True\n",
       "telecommuting          False\n",
       "has_company_logo       False\n",
       "has_questions          False\n",
       "employment_type        False\n",
       "required_experience    False\n",
       "required_education     False\n",
       "industry               False\n",
       "function               False\n",
       "fraudulent             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Ritvik\n",
      "[nltk_data]     Bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_profile         True\n",
       "description             True\n",
       "requirements            True\n",
       "benefits                True\n",
       "telecommuting          False\n",
       "has_company_logo       False\n",
       "has_questions          False\n",
       "employment_type        False\n",
       "required_experience    False\n",
       "required_education     False\n",
       "industry               False\n",
       "function               False\n",
       "fraudulent             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function\n",
       "Other                     6780\n",
       "Information Technology    1749\n",
       "Sales                     1468\n",
       "Engineering               1348\n",
       "Customer Service          1229\n",
       "Marketing                  830\n",
       "Administrative             630\n",
       "Design                     340\n",
       "Health Care Provider       338\n",
       "Education                  325\n",
       "Management                 317\n",
       "Business Development       228\n",
       "Accounting/Auditing        212\n",
       "Human Resources            205\n",
       "Project Management         183\n",
       "Finance                    172\n",
       "Consulting                 144\n",
       "Writing/Editing            132\n",
       "Art/Creative               132\n",
       "Production                 116\n",
       "Product Management         114\n",
       "Quality Assurance          111\n",
       "Advertising                 90\n",
       "Business Analyst            84\n",
       "Data Analyst                82\n",
       "Public Relations            76\n",
       "Manufacturing               74\n",
       "General Business            68\n",
       "Research                    50\n",
       "Legal                       47\n",
       "Strategy/Planning           46\n",
       "Training                    38\n",
       "Supply Chain                36\n",
       "Financial Analyst           33\n",
       "Distribution                24\n",
       "Purchasing                  15\n",
       "Science                     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['function'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "industry\n",
       "Other                                  4903\n",
       "Information Technology and Services    1734\n",
       "Computer Software                      1376\n",
       "Internet                               1062\n",
       "Marketing and Advertising               828\n",
       "                                       ... \n",
       "Shipbuilding                              1\n",
       "Sporting Goods                            1\n",
       "Museums and Institutions                  1\n",
       "Wine and Spirits                          1\n",
       "Ranching                                  1\n",
       "Name: count, Length: 132, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['industry'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment_type\n",
       "Full-time    11620\n",
       "Other         3698\n",
       "Contract      1524\n",
       "Part-time      797\n",
       "Temporary      241\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['employment_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "required_experience\n",
       "Not Applicable      8166\n",
       "Mid-Senior level    3809\n",
       "Entry level         2697\n",
       "Associate           2297\n",
       "Director             389\n",
       "Internship           381\n",
       "Executive            141\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['required_experience'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "required_education\n",
       "Unspecified                          9502\n",
       "Bachelor's Degree                    5145\n",
       "High School or equivalent            2080\n",
       "Master's Degree                       416\n",
       "Associate Degree                      274\n",
       "Certification                         170\n",
       "Some College Coursework Completed     102\n",
       "Professional                           74\n",
       "Vocational                             49\n",
       "Some High School Coursework            27\n",
       "Doctorate                              26\n",
       "Vocational - HS Diploma                 9\n",
       "Vocational - Degree                     6\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['required_education'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['company_profile'] = df['company_profile'].fillna(\"Unknown\")\n",
    "df['description'] = df['description'].fillna(\"Unknown\")\n",
    "df['requirements'] = df['requirements'].fillna(\"Unknown\")\n",
    "df['benefits'] = df['benefits'].fillna(\"None\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "company_profile        False\n",
       "description            False\n",
       "requirements           False\n",
       "benefits               False\n",
       "telecommuting          False\n",
       "has_company_logo       False\n",
       "has_questions          False\n",
       "employment_type        False\n",
       "required_experience    False\n",
       "required_education     False\n",
       "industry               False\n",
       "function               False\n",
       "fraudulent             False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ritvik\n",
      "[nltk_data]     Bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_length: 128\n",
      "Tokenized and padded text shape: (17880, 128)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "df['company_profile'] = df['company_profile'].fillna(\"\")\n",
    "\n",
    "# Text Preprocessing: Cleaning + Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.discard('not')  # Keeping the \"not\" for sentiment preservation\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', text).lower().split()\n",
    "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]\n",
    "    return \" \".join(text)\n",
    "\n",
    "df['company_profile'] = df['company_profile'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_company_profile = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  # Keep top 5000 words\n",
    "tokenizer_company_profile.fit_on_texts(df['company_profile'])\n",
    "sequences = tokenizer_company_profile.texts_to_sequences(df['company_profile'])\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]  \n",
    "max_length = int(np.percentile(lengths, 90))\n",
    "X_text_company_profile = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Optimal max_length:\", max_length)\n",
    "\n",
    "print(\"Tokenized and padded text shape:\", X_text_company_profile.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        food created groundbreaking award winning cook...\n",
       "1        second world cloud video production service se...\n",
       "2        valor service provides workforce solution meet...\n",
       "3        passion improving quality life geography heart...\n",
       "4        spotsource solution llc global human capital m...\n",
       "                               ...                        \n",
       "17875    vend looking awesome new talent come join u wo...\n",
       "17876    weblinc e commerce platform service provider f...\n",
       "17877    provide full time permanent position many medi...\n",
       "17878                                              unknown\n",
       "17879    vend looking awesome new talent come join u wo...\n",
       "Name: company_profile, Length: 17880, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['company_profile']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 244  316 2214 ...    0    0    0]\n",
      " [ 370  388  113 ... 2411  559    6]\n",
      " [ 324    3  203 ...    0    0    0]\n",
      " ...\n",
      " [  33   61   22 ...    0    0    0]\n",
      " [  30    0    0 ...    0    0    0]\n",
      " [ 592  483  213 ...   44  556  205]]\n"
     ]
    }
   ],
   "source": [
    "print(X_text_company_profile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ritvik\n",
      "[nltk_data]     Bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_length: 219\n",
      "Tokenized and padded text shape: (17880, 219)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "df['description'] = df['description'].fillna(\"\")\n",
    "\n",
    "# Text Preprocessing: Cleaning + Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.discard('not')  # Keep \"not\" for sentiment preservation\n",
    "\n",
    "\n",
    "\n",
    "df['description'] = df['description'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_description = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  # Keep top 5000 words\n",
    "tokenizer_description.fit_on_texts(df['description'])\n",
    "sequences = tokenizer_description.texts_to_sequences(df['description'])\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]  \n",
    "max_length = int(np.percentile(lengths, 90))\n",
    "X_text_description = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Optimal max_length:\", max_length)\n",
    "\n",
    "print(\"Tokenized and padded text shape:\", X_text_description.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        food fast growing james beard award winning on...\n",
       "1        organised focused vibrant awesome passion cust...\n",
       "2        client located houston actively seeking experi...\n",
       "3        company esri environmental system research ins...\n",
       "4        job title itemization review managerlocation f...\n",
       "                               ...                        \n",
       "17875    case first time visited website vend award win...\n",
       "17876    payroll accountant focus primarily payroll fun...\n",
       "17877    experienced project cost control staff enginee...\n",
       "17878    nemsia studio looking experienced visual graph...\n",
       "17879    vend award winning web based point sale softwa...\n",
       "Name: description, Length: 17880, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 406  120   69 ...    0    0    0]\n",
      " [2733  438 1818 ...    0    0    0]\n",
      " [  10  417 1701 ...    0    0    0]\n",
      " ...\n",
      " [ 194   17  179 ...    0    0    0]\n",
      " [   1 1106   18 ...    0    0    0]\n",
      " [1159  591  669 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_text_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ritvik\n",
      "[nltk_data]     Bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_length: 122\n",
      "Tokenized and padded text shape: (17880, 122)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "df['requirements'] = df['requirements'].fillna(\"\")\n",
    "\n",
    "# Text Preprocessing: Cleaning + Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.discard('not')  # Keep \"not\" for sentiment preservation\n",
    "\n",
    "\n",
    "df['requirements'] = df['requirements'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_requirements = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  # Keep top 5000 words\n",
    "tokenizer_requirements.fit_on_texts(df['requirements'])\n",
    "sequences = tokenizer_requirements.texts_to_sequences(df['requirements'])\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]  \n",
    "max_length = int(np.percentile(lengths, 90))\n",
    "X_text_requirements = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Optimal max_length:\", max_length)\n",
    "\n",
    "print(\"Tokenized and padded text shape:\", X_text_requirements.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        experience content management system major plu...\n",
       "1        expect key responsibility communicate client s...\n",
       "2        implement pre commissioning commissioning proc...\n",
       "3        education bachelor master gi business administ...\n",
       "4        qualification rn license state texasdiploma ba...\n",
       "                               ...                        \n",
       "17875    ace role eat comprehensive statement work brea...\n",
       "17876    b b accounting desire fun love genuine passion...\n",
       "17877    least year professional experience ability wor...\n",
       "17878    must fluent latest version corel amp adobe cc ...\n",
       "17879    want hear depth understanding oo programmingyo...\n",
       "Name: requirements, Length: 17880, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['requirements']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2  179   11 ...    0    0    0]\n",
      " [ 290  186   65 ...  491  196 2354]\n",
      " [ 281 3465 3465 ...  663   23 1895]\n",
      " ...\n",
      " [  69    5   72 ...    0    0    0]\n",
      " [  12  453  721 ...    0    0    0]\n",
      " [ 330 1390  620 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_text_requirements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to C:\\Users\\Ritvik\n",
      "[nltk_data]     Bhardwaj\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal max_length: 62\n",
      "Tokenized and padded text shape: (17880, 62)\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "nltk.download('wordnet')\n",
    "\n",
    "\n",
    "# Fill missing values\n",
    "df['benefits'] = df['benefits'].fillna(\"\")\n",
    "\n",
    "# Text Preprocessing: Cleaning + Lemmatization\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stop_words.discard('not')  # Keep \"not\" for sentiment preservation\n",
    "\n",
    "\n",
    "df['benefits'] = df['benefits'].apply(preprocess_text)\n",
    "\n",
    "# Tokenization\n",
    "tokenizer_benefits = Tokenizer(num_words=5000, oov_token=\"<OOV>\")  # Keep top 5000 words\n",
    "tokenizer_benefits.fit_on_texts(df['benefits'])\n",
    "sequences = tokenizer_benefits.texts_to_sequences(df['benefits'])\n",
    "\n",
    "lengths = [len(seq) for seq in sequences]  \n",
    "max_length = int(np.percentile(lengths, 90))\n",
    "X_text_benefits = pad_sequences(sequences, maxlen=max_length, padding='post')\n",
    "print(\"Optimal max_length:\", max_length)\n",
    "\n",
    "print(\"Tokenized and padded text shape:\", X_text_benefits.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                     none\n",
       "1        get usthrough part second team gain experience...\n",
       "2                                                     none\n",
       "3        culture anything corporate collaborative creat...\n",
       "4                                     full benefit offered\n",
       "                               ...                        \n",
       "17875    expect u open culture openly share result inpu...\n",
       "17876    health amp wellnessmedical planprescription dr...\n",
       "17877                                                 none\n",
       "17878    competitive salary compensation based experien...\n",
       "17879                                                 none\n",
       "Name: benefits, Length: 17880, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['benefits']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   2    0    0 ...    0    0    0]\n",
      " [ 515 3060   30 ...  126 2024  106]\n",
      " [   2    0    0 ...    0    0    0]\n",
      " ...\n",
      " [   2    0    0 ...    0    0    0]\n",
      " [   6    9   54 ...    0    0    0]\n",
      " [   2    0    0 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_text_benefits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17880, 5)\n"
     ]
    }
   ],
   "source": [
    "categorical_cols = ['employment_type', 'required_experience', 'required_education', 'industry', 'function']\n",
    "print(df[categorical_cols].shape)  # Should be (17880, 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After One-Hot Encoding: (17880, 194)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "one_hot_enc = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Transform categorical features\n",
    "X_categorical = one_hot_enc.fit_transform(df[categorical_cols])\n",
    "\n",
    "# Check shape after encoding\n",
    "print(\"After One-Hot Encoding:\", X_categorical.shape)  # Should be (17880, N)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 1. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 1. 0. ... 0. 0. 0.]\n",
      " [1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(X_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before reshaping: (17880, 194)\n"
     ]
    }
   ],
   "source": [
    "print(\"Before reshaping:\", X_categorical.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text_company_profile = np.array(X_text_company_profile)\n",
    "X_text_description = np.array(X_text_description)\n",
    "X_text_requirements = np.array(X_text_requirements)\n",
    "X_text_benefits = np.array(X_text_benefits)\n",
    "X_categorical = np.array(X_categorical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boolean Features Shape: (17880, 3)\n"
     ]
    }
   ],
   "source": [
    "# Select boolean features\n",
    "boolean_features = ['has_company_logo', 'telecommuting', 'has_questions']\n",
    "\n",
    "# Convert to numpy array\n",
    "X_boolean = df[boolean_features].values\n",
    "print(\"Boolean Features Shape:\", X_boolean.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_final = np.hstack([\n",
    "    X_text_company_profile, \n",
    "    X_text_description, \n",
    "    X_text_requirements, \n",
    "    X_text_benefits, \n",
    "    X_categorical,\n",
    "    X_boolean\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.440e+02 3.160e+02 2.214e+03 ... 1.000e+00 0.000e+00 0.000e+00]\n",
      " [3.700e+02 3.880e+02 1.130e+02 ... 1.000e+00 0.000e+00 0.000e+00]\n",
      " [3.240e+02 3.000e+00 2.030e+02 ... 1.000e+00 0.000e+00 0.000e+00]\n",
      " ...\n",
      " [3.300e+01 6.100e+01 2.200e+01 ... 0.000e+00 0.000e+00 0.000e+00]\n",
      " [3.000e+01 0.000e+00 0.000e+00 ... 0.000e+00 0.000e+00 1.000e+00]\n",
      " [5.920e+02 4.830e+02 2.130e+02 ... 1.000e+00 0.000e+00 1.000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y = df['fraudulent'].values\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.15.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.6.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ritvik bhardwaj\\anaconda3\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Ritvik Bhardwaj\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution after SMOTE: Counter({0: 17014, 1: 8507})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(sampling_strategy=0.5, random_state=42)\n",
    "X_balanced, y_balanced = smote.fit_resample(X_final, y)\n",
    "\n",
    "# Check new class distribution\n",
    "from collections import Counter\n",
    "print(\"Class distribution after SMOTE:\", Counter(y_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.44000000e+02 3.16000000e+02 2.21400000e+03 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.70000000e+02 3.88000000e+02 1.13000000e+02 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [3.24000000e+02 3.00000000e+00 2.03000000e+02 ... 1.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " ...\n",
      " [3.91504176e+01 2.61440502e-01 2.09152402e+00 ... 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [8.68932106e+00 4.48259109e+01 2.20455299e+00 ... 7.34850998e-01\n",
      "  0.00000000e+00 7.34850998e-01]\n",
      " [3.00000000e+01 0.00000000e+00 0.00000000e+00 ... 1.68933551e-02\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print(X_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25521, 728)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25521,)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_balanced.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_balanced,y_balanced,test_size = 0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 5ms/step - accuracy: 0.7999 - loss: 0.4072 - val_accuracy: 0.9365 - val_loss: 0.1560\n",
      "Epoch 2/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - accuracy: 0.9410 - loss: 0.1500 - val_accuracy: 0.9628 - val_loss: 0.0939\n",
      "Epoch 3/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 5ms/step - accuracy: 0.9642 - loss: 0.0954 - val_accuracy: 0.9661 - val_loss: 0.0873\n",
      "Epoch 4/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9738 - loss: 0.0736 - val_accuracy: 0.9769 - val_loss: 0.0647\n",
      "Epoch 5/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9753 - loss: 0.0662 - val_accuracy: 0.9773 - val_loss: 0.0567\n",
      "Epoch 6/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9782 - loss: 0.0575 - val_accuracy: 0.9771 - val_loss: 0.0603\n",
      "Epoch 7/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9834 - loss: 0.0474 - val_accuracy: 0.9783 - val_loss: 0.0525\n",
      "Epoch 8/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0396 - val_accuracy: 0.9802 - val_loss: 0.0526\n",
      "Epoch 9/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9842 - loss: 0.0414 - val_accuracy: 0.9816 - val_loss: 0.0447\n",
      "Epoch 10/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0362 - val_accuracy: 0.9845 - val_loss: 0.0422\n",
      "Epoch 11/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9883 - loss: 0.0321 - val_accuracy: 0.9810 - val_loss: 0.0476\n",
      "Epoch 12/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9899 - loss: 0.0291 - val_accuracy: 0.9867 - val_loss: 0.0331\n",
      "Epoch 13/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 9ms/step - accuracy: 0.9895 - loss: 0.0299 - val_accuracy: 0.9853 - val_loss: 0.0394\n",
      "Epoch 14/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - accuracy: 0.9903 - loss: 0.0291 - val_accuracy: 0.9873 - val_loss: 0.0316\n",
      "Epoch 15/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 6ms/step - accuracy: 0.9911 - loss: 0.0259 - val_accuracy: 0.9869 - val_loss: 0.0349\n",
      "Epoch 16/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0260 - val_accuracy: 0.9873 - val_loss: 0.0383\n",
      "Epoch 17/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0288 - val_accuracy: 0.9871 - val_loss: 0.0338\n",
      "Epoch 18/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0217 - val_accuracy: 0.9875 - val_loss: 0.0353\n",
      "Epoch 19/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9927 - loss: 0.0217 - val_accuracy: 0.9857 - val_loss: 0.0457\n",
      "Epoch 20/20\n",
      "\u001b[1m638/638\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9914 - loss: 0.0228 - val_accuracy: 0.9884 - val_loss: 0.0341\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Define the MLP model\n",
    "model = Sequential([\n",
    "    Input(shape=(X_train.shape[1],)),  # Input layer matching feature size\n",
    "    Dense(256, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(128, activation='relu'),\n",
    "    BatchNormalization(),\n",
    "    Dropout(0.3),\n",
    "\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')  # Binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=Adam(learning_rate=0.0005), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(X_train, y_train, epochs=20, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for prediction: (5105, 728)\n"
     ]
    }
   ],
   "source": [
    "print(\"Input shape for prediction:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9905 - loss: 0.0328\n",
      "Test Accuracy: 98.84%\n",
      "\u001b[1m160/160\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " ...\n",
      " [0]\n",
      " [0]\n",
      " [1]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99      3412\n",
      "           1       0.97      1.00      0.98      1693\n",
      "\n",
      "    accuracy                           0.99      5105\n",
      "   macro avg       0.98      0.99      0.99      5105\n",
      "weighted avg       0.99      0.99      0.99      5105\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on Test Set\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "\n",
    "print(f\"Test Accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "# Generate Classification Report\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
    "print(y_pred)\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved successfully!\n"
     ]
    }
   ],
   "source": [
    "model.save(\"fake_job_detection.h5\")\n",
    "print(\"Model saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer saved successfully!\n",
      "OneHotEncoder saved successfully!\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the tokenizer\n",
    "joblib.dump(tokenizer_company_profile, \"tokenizer_company_profile.pkl\")\n",
    "joblib.dump(tokenizer_description, \"tokenizer_description.pkl\")\n",
    "joblib.dump(tokenizer_requirements, \"tokenizer_requirements.pkl\")\n",
    "joblib.dump(tokenizer_benefits, \"tokenizer_benefits.pkl\")\n",
    "\n",
    "print(\"Tokenizer saved successfully!\")\n",
    "joblib.dump(one_hot_enc, \"one_hot_encoder.pkl\")\n",
    "print(\"OneHotEncoder saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original class distribution: Counter({0: 17014, 1: 866})\n",
      "After SMOTE: Counter({0: 17014, 1: 8507})\n"
     ]
    }
   ],
   "source": [
    "print(\"Original class distribution:\", Counter(y))\n",
    "print(\"After SMOTE:\", Counter(y_balanced))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step\n",
      "[[0.9978559]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.models.load_model(\"fake_job_detection.h5\")\n",
    "\n",
    "# Create a random input of the expected shape\n",
    "random_input = np.random.rand(1, 728)\n",
    "\n",
    "# Run prediction\n",
    "output = model.predict(random_input)\n",
    "print(output)  # This should print a valid prediction between 0 and 1\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
